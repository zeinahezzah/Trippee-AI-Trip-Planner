// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
import { isUnexpected, } from "../rest/index.js";
export function _getEmbeddingsSend(context, input, deploymentId, options = { requestOptions: {} }) {
    var _a, _b, _c;
    return context.path("/deployments/{deploymentId}/embeddings", deploymentId).post({
        allowInsecureConnection: (_a = options.requestOptions) === null || _a === void 0 ? void 0 : _a.allowInsecureConnection,
        skipUrlEncoding: (_b = options.requestOptions) === null || _b === void 0 ? void 0 : _b.skipUrlEncoding,
        headers: Object.assign({}, (_c = options.requestOptions) === null || _c === void 0 ? void 0 : _c.headers),
        body: { user: options === null || options === void 0 ? void 0 : options.user, model: options === null || options === void 0 ? void 0 : options.model, input: input },
    });
}
export async function _getEmbeddingsDeserialize(result) {
    var _a;
    if (isUnexpected(result)) {
        throw result.body;
    }
    return {
        data: ((_a = result.body["data"]) !== null && _a !== void 0 ? _a : []).map((p) => ({
            embedding: p["embedding"],
            index: p["index"],
        })),
        usage: {
            promptTokens: result.body.usage["prompt_tokens"],
            totalTokens: result.body.usage["total_tokens"],
        },
    };
}
/** Return the embeddings for a given prompt. */
export async function getEmbeddings(context, input, deploymentId, options = { requestOptions: {} }) {
    const result = await _getEmbeddingsSend(context, input, deploymentId, options);
    return _getEmbeddingsDeserialize(result);
}
export function _getCompletionsSend(context, prompt, deploymentId, options = { requestOptions: {} }) {
    var _a, _b, _c;
    return context.path("/deployments/{deploymentId}/completions", deploymentId).post({
        allowInsecureConnection: (_a = options.requestOptions) === null || _a === void 0 ? void 0 : _a.allowInsecureConnection,
        skipUrlEncoding: (_b = options.requestOptions) === null || _b === void 0 ? void 0 : _b.skipUrlEncoding,
        headers: Object.assign({}, (_c = options.requestOptions) === null || _c === void 0 ? void 0 : _c.headers),
        body: {
            prompt: prompt,
            max_tokens: options === null || options === void 0 ? void 0 : options.maxTokens,
            temperature: options === null || options === void 0 ? void 0 : options.temperature,
            top_p: options === null || options === void 0 ? void 0 : options.topP,
            logit_bias: options === null || options === void 0 ? void 0 : options.logitBias,
            user: options === null || options === void 0 ? void 0 : options.user,
            n: options === null || options === void 0 ? void 0 : options.n,
            logprobs: options === null || options === void 0 ? void 0 : options.logprobs,
            echo: options === null || options === void 0 ? void 0 : options.echo,
            stop: options === null || options === void 0 ? void 0 : options.stop,
            presence_penalty: options === null || options === void 0 ? void 0 : options.presencePenalty,
            frequency_penalty: options === null || options === void 0 ? void 0 : options.frequencyPenalty,
            best_of: options === null || options === void 0 ? void 0 : options.bestOf,
            stream: options === null || options === void 0 ? void 0 : options.stream,
            model: options === null || options === void 0 ? void 0 : options.model,
        },
    });
}
export async function _getCompletionsDeserialize(result) {
    var _a;
    if (isUnexpected(result)) {
        throw result.body;
    }
    return {
        id: result.body["id"],
        created: result.body["created"],
        choices: ((_a = result.body["choices"]) !== null && _a !== void 0 ? _a : []).map((p) => ({
            text: p["text"],
            index: p["index"],
            logprobs: p.logprobs === null
                ? null
                : {
                    tokens: p.logprobs["tokens"],
                    tokenLogprobs: p.logprobs["token_logprobs"],
                    topLogprobs: p.logprobs["top_logprobs"],
                    textOffset: p.logprobs["text_offset"],
                },
            finishReason: p["finish_reason"],
        })),
        usage: {
            completionTokens: result.body.usage["completion_tokens"],
            promptTokens: result.body.usage["prompt_tokens"],
            totalTokens: result.body.usage["total_tokens"],
        },
    };
}
/**
 * Gets completions for the provided input prompts.
 * Completions support a wide variety of tasks and generate text that continues from or "completes"
 * provided prompt data.
 */
export async function getCompletions(context, prompt, deploymentId, options = { requestOptions: {} }) {
    const result = await _getCompletionsSend(context, prompt, deploymentId, options);
    return _getCompletionsDeserialize(result);
}
export function _getChatCompletionsSend(context, messages, deploymentId, options = { requestOptions: {} }) {
    var _a, _b, _c;
    return context.path("/deployments/{deploymentId}/chat/completions", deploymentId).post({
        allowInsecureConnection: (_a = options.requestOptions) === null || _a === void 0 ? void 0 : _a.allowInsecureConnection,
        skipUrlEncoding: (_b = options.requestOptions) === null || _b === void 0 ? void 0 : _b.skipUrlEncoding,
        headers: Object.assign({}, (_c = options.requestOptions) === null || _c === void 0 ? void 0 : _c.headers),
        body: {
            messages: messages,
            max_tokens: options === null || options === void 0 ? void 0 : options.maxTokens,
            temperature: options === null || options === void 0 ? void 0 : options.temperature,
            top_p: options === null || options === void 0 ? void 0 : options.topP,
            logit_bias: options === null || options === void 0 ? void 0 : options.logitBias,
            user: options === null || options === void 0 ? void 0 : options.user,
            n: options === null || options === void 0 ? void 0 : options.n,
            stop: options === null || options === void 0 ? void 0 : options.stop,
            presence_penalty: options === null || options === void 0 ? void 0 : options.presencePenalty,
            frequency_penalty: options === null || options === void 0 ? void 0 : options.frequencyPenalty,
            stream: options === null || options === void 0 ? void 0 : options.stream,
            model: options === null || options === void 0 ? void 0 : options.model,
        },
    });
}
export async function _getChatCompletionsDeserialize(result) {
    var _a;
    if (isUnexpected(result)) {
        throw result.body;
    }
    return {
        id: result.body["id"],
        created: result.body["created"],
        choices: ((_a = result.body["choices"]) !== null && _a !== void 0 ? _a : []).map((p) => {
            var _a, _b, _c, _d;
            return ({
                message: !p.message
                    ? undefined
                    : { role: (_a = p.message) === null || _a === void 0 ? void 0 : _a["role"], content: (_b = p.message) === null || _b === void 0 ? void 0 : _b["content"] },
                index: p["index"],
                finishReason: p["finish_reason"],
                delta: !p.delta ? undefined : { role: (_c = p.delta) === null || _c === void 0 ? void 0 : _c["role"], content: (_d = p.delta) === null || _d === void 0 ? void 0 : _d["content"] },
            });
        }),
        usage: {
            completionTokens: result.body.usage["completion_tokens"],
            promptTokens: result.body.usage["prompt_tokens"],
            totalTokens: result.body.usage["total_tokens"],
        },
    };
}
/**
 * Gets chat completions for the provided chat messages.
 * Completions support a wide variety of tasks and generate text that continues from or "completes"
 * provided prompt data.
 */
export async function getChatCompletions(context, messages, deploymentId, options = { requestOptions: {} }) {
    const result = await _getChatCompletionsSend(context, messages, deploymentId, options);
    return _getChatCompletionsDeserialize(result);
}
export function _getAzureBatchImageGenerationOperationStatusSend(context, operationId, options = {
    requestOptions: {},
}) {
    var _a, _b, _c;
    return context.path("/operations/images/{operationId}", operationId).get({
        allowInsecureConnection: (_a = options.requestOptions) === null || _a === void 0 ? void 0 : _a.allowInsecureConnection,
        skipUrlEncoding: (_b = options.requestOptions) === null || _b === void 0 ? void 0 : _b.skipUrlEncoding,
        headers: Object.assign({}, (_c = options.requestOptions) === null || _c === void 0 ? void 0 : _c.headers),
    });
}
export async function _getAzureBatchImageGenerationOperationStatusDeserialize(result) {
    var _a, _b;
    if (isUnexpected(result)) {
        throw result.body;
    }
    return {
        id: result.body["id"],
        created: result.body["created"],
        expires: result.body["expires"],
        result: !result.body.result
            ? undefined
            : {
                created: (_a = result.body.result) === null || _a === void 0 ? void 0 : _a["created"],
                data: toImageGenerationsData((_b = result.body.result) === null || _b === void 0 ? void 0 : _b["data"]),
            },
        status: result.body["status"],
        error: !result.body.error ? undefined : result.body.error,
    };
}
/**
 * Convert REST-level ImageGenerationsOutput.data to HLC-level ImageGenerations.data
 * see https://github.com/Azure/autorest.typescript/issues/1921
 * @internal
 */
function toImageGenerationsData(input) {
    return input.map(function (locationOrPayload) {
        if ("url" in locationOrPayload) {
            return locationOrPayload;
        }
        else {
            return {
                base64Data: locationOrPayload.b64_json,
            };
        }
    });
}
/** Returns the status of the images operation */
export async function getAzureBatchImageGenerationOperationStatus(context, operationId, options = {
    requestOptions: {},
}) {
    const result = await _getAzureBatchImageGenerationOperationStatusSend(context, operationId, options);
    return _getAzureBatchImageGenerationOperationStatusDeserialize(result);
}
export function _beginAzureBatchImageGenerationSend(context, prompt, options = { requestOptions: {} }) {
    var _a, _b, _c, _d;
    return context.path("/images/generations:submit").post({
        allowInsecureConnection: (_a = options.requestOptions) === null || _a === void 0 ? void 0 : _a.allowInsecureConnection,
        skipUrlEncoding: (_b = options.requestOptions) === null || _b === void 0 ? void 0 : _b.skipUrlEncoding,
        headers: Object.assign({}, (_c = options.requestOptions) === null || _c === void 0 ? void 0 : _c.headers),
        body: {
            prompt: prompt,
            n: (_d = options.n) !== null && _d !== void 0 ? _d : 1,
            size: options === null || options === void 0 ? void 0 : options.size,
            response_format: options === null || options === void 0 ? void 0 : options.responseFormat,
            user: options === null || options === void 0 ? void 0 : options.user,
        },
    });
}
export async function _beginAzureBatchImageGenerationDeserialize(result) {
    var _a, _b;
    if (isUnexpected(result)) {
        throw result.body;
    }
    return {
        id: result.body["id"],
        created: result.body["created"],
        expires: result.body["expires"],
        result: !result.body.result
            ? undefined
            : {
                created: (_a = result.body.result) === null || _a === void 0 ? void 0 : _a["created"],
                data: toImageGenerationsData((_b = result.body.result) === null || _b === void 0 ? void 0 : _b["data"]),
            },
        status: result.body["status"],
        error: !result.body.error ? undefined : result.body.error,
    };
}
/** Starts the generation of a batch of images from a text caption */
export async function beginAzureBatchImageGeneration(context, prompt, options = { requestOptions: {} }) {
    const result = await _beginAzureBatchImageGenerationSend(context, prompt, options);
    return _beginAzureBatchImageGenerationDeserialize(result);
}
export function getCompletionsResult(body) {
    var _a;
    return {
        id: body["id"],
        created: body["created"],
        choices: ((_a = body["choices"]) !== null && _a !== void 0 ? _a : []).map((p) => ({
            text: p["text"],
            index: p["index"],
            logprobs: p.logprobs === null
                ? null
                : {
                    tokens: p.logprobs["tokens"],
                    tokenLogprobs: p.logprobs["token_logprobs"],
                    topLogprobs: p.logprobs["top_logprobs"],
                    textOffset: p.logprobs["text_offset"],
                },
            finishReason: p["finish_reason"],
        })),
    };
}
export function getChatCompletionsResult(body) {
    var _a;
    return {
        id: body["id"],
        created: body["created"],
        choices: ((_a = body["choices"]) !== null && _a !== void 0 ? _a : []).map((p) => {
            var _a, _b, _c, _d;
            return ({
                message: !p.message
                    ? undefined
                    : { role: (_a = p.message) === null || _a === void 0 ? void 0 : _a["role"], content: (_b = p.message) === null || _b === void 0 ? void 0 : _b["content"] },
                index: p["index"],
                finishReason: p["finish_reason"],
                delta: !p.delta ? undefined : { role: (_c = p.delta) === null || _c === void 0 ? void 0 : _c["role"], content: (_d = p.delta) === null || _d === void 0 ? void 0 : _d["content"] },
            });
        }),
    };
}
//# sourceMappingURL=operations.js.map