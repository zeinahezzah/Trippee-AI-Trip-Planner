{"version":3,"file":"OpenAIClient.js","sourceRoot":"","sources":["../../src/OpenAIClient.ts"],"names":[],"mappings":"AAAA,uCAAuC;AACvC,kCAAkC;;AAElC;;;;;;GAMG;AAEH,OAAO,EAAkC,iBAAiB,EAAE,MAAM,kBAAkB,CAAC;AACrF,OAAO,EAAE,YAAY,EAAE,MAAM,wBAAwB,CAAC;AACtD,OAAO,EACL,uBAAuB,EACvB,mBAAmB,EACnB,8BAA8B,EAC9B,2CAA2C,EAC3C,kBAAkB,EAClB,wBAAwB,EACxB,cAAc,EACd,oBAAoB,EACpB,aAAa,GACd,MAAM,qBAAqB,CAAC;AAe7B,OAAO,EAAE,OAAO,EAAE,MAAM,cAAc,CAAC;AAIvC,MAAM,OAAO,YAAY;IAgCvB,YACE,mBAA2C,EAC3C,gBAAuE,EAAE,EACzE,UAA+B,EAAE;;QAjC3B,aAAQ,GAAG,KAAK,CAAC;QAmCvB,IAAI,IAAyB,CAAC;QAC9B,IAAI,QAAgB,CAAC;QACrB,IAAI,IAAqC,CAAC;QAC1C,IAAI,MAAM,CAAC,aAAa,CAAC,EAAE;YACzB,QAAQ,GAAG,mBAA6B,CAAC;YACzC,IAAI,GAAG,aAAa,CAAC;YACrB,IAAI,GAAG,OAAO,CAAC;YACf,IAAI,CAAC,QAAQ,GAAG,IAAI,CAAC;SACtB;aAAM;YACL,QAAQ,GAAG,oBAAoB,CAAC,CAAC,CAAC,CAAC;YACnC,IAAI,GAAG,mBAAoC,CAAC;YAC5C,MAAM,EAAE,WAAW,KAAkB,aAAa,EAA1B,QAAQ,UAAK,aAAa,EAA5C,eAA4B,CAAgB,CAAC;YACnD,IAAI,mBACF,WAAW,EAAE;oBACX,gBAAgB,EAAE,MAAA,WAAW,aAAX,WAAW,uBAAX,WAAW,CAAE,gBAAgB,mCAAI,eAAe;oBAClE,MAAM,EAAE,WAAW,aAAX,WAAW,uBAAX,WAAW,CAAE,MAAM;iBAC5B,IACE,QAAQ,CACZ,CAAC;SACH;QAED,IAAI,CAAC,OAAO,GAAG,YAAY,CAAC,QAAQ,EAAE,IAAI,kCACrC,IAAI,GACJ,CAAC,IAAI,CAAC,QAAQ;YACf,CAAC,CAAC,EAAE;YACJ,CAAC,CAAC;gBACE,kBAAkB,EAAE;oBAClB,GAAG,CAAC,MAAA,IAAI,CAAC,kBAAkB,mCAAI,EAAE,CAAC;oBAClC;wBACE,QAAQ,EAAE,SAAS;wBACnB,MAAM,EAAE;4BACN,IAAI,EAAE,gBAAgB;4BACtB,WAAW,EAAE,CAAC,OAAO,EAAE,IAAI,EAAE,EAAE;gCAC7B,MAAM,GAAG,GAAG,IAAI,GAAG,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC;gCACjC,MAAM,KAAK,GAAG,GAAG,CAAC,QAAQ,CAAC,KAAK,CAAC,GAAG,CAAC,CAAC;gCACtC,GAAG,CAAC,QAAQ,GAAG,IAAI,KAAK,CAAC,CAAC,CAAC,IAAI,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC;gCAC1D,GAAG,CAAC,YAAY,CAAC,MAAM,CAAC,aAAa,CAAC,CAAC;gCACvC,OAAO,CAAC,GAAG,GAAG,GAAG,CAAC,QAAQ,EAAE,CAAC;gCAC7B,OAAO,IAAI,CAAC,OAAO,CAAC,CAAC;4BACvB,CAAC;yBACF;qBACF;iBACF;aACF,CAAC,EACN,CAAC;IACL,CAAC;IAED,iDAAiD;IACjD,2CAA2C,CACzC,WAAmB,EACnB,UAA8D;QAC5D,cAAc,EAAE,EAAE;KACnB;QAED,OAAO,2CAA2C,CAAC,IAAI,CAAC,OAAO,EAAE,WAAW,EAAE,OAAO,CAAC,CAAC;IACzF,CAAC;IAED,qEAAqE;IACrE,8BAA8B,CAC5B,MAAc,EACd,UAAkC,EAAE,cAAc,EAAE,EAAE,EAAE;QAExD,OAAO,8BAA8B,CAAC,IAAI,CAAC,OAAO,EAAE,MAAM,EAAE,OAAO,CAAC,CAAC;IACvE,CAAC;IAED;;;;;OAKG;IACH,SAAS,CACP,MAAc,EACd,UAAkC,EAAE,cAAc,EAAE,EAAE,EAAE;QAExD,OAAO,8BAA8B,CAAC,IAAI,CAAC,OAAO,EAAE,MAAM,EAAE,OAAO,CAAC,CAAC;IACvE,CAAC;IAED;;;;;;OAMG;IACH,cAAc,CACZ,qBAA6B,EAC7B,MAAgB,EAChB,UAAiC,EAAE,cAAc,EAAE,EAAE,EAAE;QAEvD,IAAI,CAAC,QAAQ,CAAC,qBAAqB,EAAE,OAAO,CAAC,CAAC;QAC9C,OAAO,cAAc,CAAC,IAAI,CAAC,OAAO,EAAE,MAAM,EAAE,qBAAqB,EAAE,OAAO,CAAC,CAAC;IAC9E,CAAC;IAED;;;;;;OAMG;IACH,eAAe,CACb,qBAA6B,EAC7B,MAAgB,EAChB,UAAiC,EAAE;QAEnC,IAAI,CAAC,QAAQ,CAAC,qBAAqB,EAAE,OAAO,CAAC,CAAC;QAC9C,MAAM,QAAQ,GAAG,mBAAmB,CAAC,IAAI,CAAC,OAAO,EAAE,MAAM,EAAE,qBAAqB,kCAC3E,OAAO,KACV,MAAM,EAAE,IAAI,IACZ,CAAC;QACH,OAAO,OAAO,CAAC,QAAQ,EAAE,oBAAoB,CAAC,CAAC;IACjD,CAAC;IAED;;;;;;OAMG;IACH,aAAa,CACX,qBAA6B,EAC7B,KAAe,EACf,UAAgC,EAAE,cAAc,EAAE,EAAE,EAAE;QAEtD,IAAI,CAAC,QAAQ,CAAC,qBAAqB,EAAE,OAAO,CAAC,CAAC;QAC9C,OAAO,aAAa,CAAC,IAAI,CAAC,OAAO,EAAE,KAAK,EAAE,qBAAqB,EAAE,OAAO,CAAC,CAAC;IAC5E,CAAC;IAED;;;;;;OAMG;IACH,kBAAkB,CAChB,qBAA6B,EAC7B,QAAuB,EACvB,UAAqC,EAAE,cAAc,EAAE,EAAE,EAAE;QAE3D,IAAI,CAAC,QAAQ,CAAC,qBAAqB,EAAE,OAAO,CAAC,CAAC;QAC9C,OAAO,kBAAkB,CAAC,IAAI,CAAC,OAAO,EAAE,QAAQ,EAAE,qBAAqB,EAAE,OAAO,CAAC,CAAC;IACpF,CAAC;IAED;;;;;;OAMG;IACH,mBAAmB,CACjB,qBAA6B,EAC7B,QAAuB,EACvB,UAAqC,EAAE,cAAc,EAAE,EAAE,EAAE;QAE3D,IAAI,CAAC,QAAQ,CAAC,qBAAqB,EAAE,OAAO,CAAC,CAAC;QAC9C,MAAM,QAAQ,GAAG,uBAAuB,CAAC,IAAI,CAAC,OAAO,EAAE,QAAQ,EAAE,qBAAqB,kCACjF,OAAO,KACV,MAAM,EAAE,IAAI,IACZ,CAAC;QACH,OAAO,OAAO,CAAC,QAAQ,EAAE,wBAAwB,CAAC,CAAC;IACrD,CAAC;IAEO,QAAQ,CAAC,KAAa,EAAE,OAA2B;QACzD,IAAI,CAAC,IAAI,CAAC,QAAQ,EAAE;YAClB,OAAO,CAAC,KAAK,GAAG,KAAK,CAAC;SACvB;IACH,CAAC;CACF;AAED,SAAS,oBAAoB,CAAC,OAAe;IAC3C,OAAO,2BAA2B,OAAO,EAAE,CAAC;AAC9C,CAAC;AAED,SAAS,MAAM,CAAC,IAAyB;IACvC,OAAO,iBAAiB,CAAC,IAAI,CAAC,IAAI,IAAI,CAAC,GAAG,KAAK,SAAS,CAAC;AAC3D,CAAC","sourcesContent":["// Copyright (c) Microsoft Corporation.\n// Licensed under the MIT license.\n\n/**\n * THIS IS AN AUTO-GENERATED FILE - DO NOT EDIT!\n *\n * Any changes you make here may be lost.\n *\n * If you need to make changes, please do so in the original source file, \\{project-root\\}/sources/custom\n */\n\nimport { KeyCredential, TokenCredential, isTokenCredential } from \"@azure/core-auth\";\nimport { createOpenAI } from \"./api/OpenAIContext.js\";\nimport {\n  _getChatCompletionsSend,\n  _getCompletionsSend,\n  beginAzureBatchImageGeneration,\n  getAzureBatchImageGenerationOperationStatus,\n  getChatCompletions,\n  getChatCompletionsResult,\n  getCompletions,\n  getCompletionsResult,\n  getEmbeddings,\n} from \"./api/operations.js\";\nimport {\n  ChatCompletions,\n  ChatMessage,\n  Completions,\n  Embeddings,\n  GetAzureBatchImageGenerationOperationStatusOptions,\n  GetChatCompletionsOptions,\n  GetCompletionsOptions,\n  GetEmbeddingsOptions,\n  ImageGenerationOptions,\n  ImageGenerationResponse,\n  OpenAIClientOptions,\n} from \"./index.js\";\nimport { OpenAIContext } from \"./rest/clientDefinitions.js\";\nimport { getSSEs } from \"./api/sse.js\";\n\nexport { OpenAIClientOptions } from \"./api/OpenAIContext.js\";\n\nexport class OpenAIClient {\n  private _client: OpenAIContext;\n  private _isAzure = false;\n\n  /**\n   * Initializes an instance of OpenAIClient for use with an Azure OpenAI resource.\n   * @param endpoint - The URI for an Azure OpenAI resource, including protocol and hostname.\n   *                 For example: https://my-resource.openai.azure.com.\n   * @param credential - A key credential used to authenticate to an Azure OpenAI resource.\n   * @param options - The options for configuring the client.\n   * @remarks\n   *   This constructor initializes an OpenAIClient object that can only be used with Azure OpenAI resources.\n   *   To use OpenAIClient with a non-Azure OpenAI inference endpoint, use a constructor that accepts a non-Azure OpenAI API key instead.\n   */\n  constructor(endpoint: string, credential: KeyCredential, options?: OpenAIClientOptions);\n  /**\n   * Initializes an instance of OpenAIClient for use with an Azure OpenAI resource.\n   * @param endpoint - The URI for an Azure OpenAI resource, including protocol and hostname.\n   *                 For example: https://my-resource.openai.azure.com.\n   * @param credential - A token credential used to authenticate with an Azure OpenAI resource.\n   * @param options - The options for configuring the client.\n   */\n  constructor(endpoint: string, credential: TokenCredential, options?: OpenAIClientOptions);\n  /**\n   * Initializes an instance of OpenAIClient for use with the non-Azure OpenAI endpoint.\n   * @param openAiApiKey - The API key to use when connecting to the non-Azure OpenAI endpoint.\n   * @param options - The options for configuring the client.\n   * @remarks\n   *   OpenAIClient objects initialized with this constructor can only be used with the non-Azure OpenAI inference endpoint.\n   *   To use OpenAIClient with an Azure OpenAI resource, use a constructor that accepts a resource URI and Azure authentication credential instead.\n   */\n  constructor(openAiApiKey: KeyCredential, options?: OpenAIClientOptions);\n  constructor(\n    endpointOrOpenAiKey: string | KeyCredential,\n    credOrOptions: KeyCredential | TokenCredential | OpenAIClientOptions = {},\n    options: OpenAIClientOptions = {}\n  ) {\n    let opts: OpenAIClientOptions;\n    let endpoint: string;\n    let cred: KeyCredential | TokenCredential;\n    if (isCred(credOrOptions)) {\n      endpoint = endpointOrOpenAiKey as string;\n      cred = credOrOptions;\n      opts = options;\n      this._isAzure = true;\n    } else {\n      endpoint = createOpenAIEndpoint(1);\n      cred = endpointOrOpenAiKey as KeyCredential;\n      const { credentials, ...restOpts } = credOrOptions;\n      opts = {\n        credentials: {\n          apiKeyHeaderName: credentials?.apiKeyHeaderName ?? \"Authorization\",\n          scopes: credentials?.scopes,\n        },\n        ...restOpts,\n      };\n    }\n\n    this._client = createOpenAI(endpoint, cred, {\n      ...opts,\n      ...(this._isAzure\n        ? {}\n        : {\n            additionalPolicies: [\n              ...(opts.additionalPolicies ?? []),\n              {\n                position: \"perCall\",\n                policy: {\n                  name: \"openAiEndpoint\",\n                  sendRequest: (request, next) => {\n                    const obj = new URL(request.url);\n                    const parts = obj.pathname.split(\"/\");\n                    obj.pathname = `/${parts[1]}/${parts.slice(5).join(\"/\")}`;\n                    obj.searchParams.delete(\"api-version\");\n                    request.url = obj.toString();\n                    return next(request);\n                  },\n                },\n              },\n            ],\n          }),\n    });\n  }\n\n  /** Returns the status of the images operation */\n  getAzureBatchImageGenerationOperationStatus(\n    operationId: string,\n    options: GetAzureBatchImageGenerationOperationStatusOptions = {\n      requestOptions: {},\n    }\n  ): Promise<ImageGenerationResponse> {\n    return getAzureBatchImageGenerationOperationStatus(this._client, operationId, options);\n  }\n\n  /** Starts the generation of a batch of images from a text caption */\n  beginAzureBatchImageGeneration(\n    prompt: string,\n    options: ImageGenerationOptions = { requestOptions: {} }\n  ): Promise<ImageGenerationResponse> {\n    return beginAzureBatchImageGeneration(this._client, prompt, options);\n  }\n\n  /**\n   * Starts the generation of a batch of images from a text caption\n   * @param prompt - The prompt to use for this request.\n   * @param options - The options for this image request.\n   * @returns The image generation response (containing url or base64 data).\n   */\n  getImages(\n    prompt: string,\n    options: ImageGenerationOptions = { requestOptions: {} }\n  ): Promise<ImageGenerationResponse> {\n    return beginAzureBatchImageGeneration(this._client, prompt, options);\n  }\n\n  /**\n   * Returns textual completions as configured for a given prompt.\n   * @param deploymentOrModelName - Specifies either the model deployment name (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.\n   * @param prompt - The prompt to use for this request.\n   * @param options - The options for this completions request.\n   * @returns The completions for the given prompt.\n   */\n  getCompletions(\n    deploymentOrModelName: string,\n    prompt: string[],\n    options: GetCompletionsOptions = { requestOptions: {} }\n  ): Promise<Completions> {\n    this.setModel(deploymentOrModelName, options);\n    return getCompletions(this._client, prompt, deploymentOrModelName, options);\n  }\n\n  /**\n   * Lists the completions tokens as they become available for a given prompt.\n   * @param deploymentOrModelName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.\n   * @param prompt - The prompt to use for this request.\n   * @param options - The completions options for this completions request.\n   * @returns An asynchronous iterable of completions tokens.\n   */\n  listCompletions(\n    deploymentOrModelName: string,\n    prompt: string[],\n    options: GetCompletionsOptions = {}\n  ): Promise<AsyncIterable<Omit<Completions, \"usage\">>> {\n    this.setModel(deploymentOrModelName, options);\n    const response = _getCompletionsSend(this._client, prompt, deploymentOrModelName, {\n      ...options,\n      stream: true,\n    });\n    return getSSEs(response, getCompletionsResult);\n  }\n\n  /**\n   * Return the computed embeddings for a given prompt.\n   * @param deploymentOrModelName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.\n   * @param input - The prompt to use for this request.\n   * @param options - The embeddings options for this embeddings request.\n   * @returns The embeddings for the given prompt.\n   */\n  getEmbeddings(\n    deploymentOrModelName: string,\n    input: string[],\n    options: GetEmbeddingsOptions = { requestOptions: {} }\n  ): Promise<Embeddings> {\n    this.setModel(deploymentOrModelName, options);\n    return getEmbeddings(this._client, input, deploymentOrModelName, options);\n  }\n\n  /**\n   * Get chat completions for provided chat context messages.\n   * @param deploymentOrModelName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.\n   * @param messages - The chat context messages to use for this request.\n   * @param options - The chat completions options for this completions request.\n   * @returns The chat completions for the given chat context messages.\n   */\n  getChatCompletions(\n    deploymentOrModelName: string,\n    messages: ChatMessage[],\n    options: GetChatCompletionsOptions = { requestOptions: {} }\n  ): Promise<ChatCompletions> {\n    this.setModel(deploymentOrModelName, options);\n    return getChatCompletions(this._client, messages, deploymentOrModelName, options);\n  }\n\n  /**\n   * Lists the chat completions tokens as they become available for a chat context.\n   * @param deploymentOrModelName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.\n   * @param messages - The chat context messages to use for this request.\n   * @param options - The chat completions options for this chat completions request.\n   * @returns An asynchronous iterable of chat completions tokens.\n   */\n  listChatCompletions(\n    deploymentOrModelName: string,\n    messages: ChatMessage[],\n    options: GetChatCompletionsOptions = { requestOptions: {} }\n  ): Promise<AsyncIterable<Omit<ChatCompletions, \"usage\">>> {\n    this.setModel(deploymentOrModelName, options);\n    const response = _getChatCompletionsSend(this._client, messages, deploymentOrModelName, {\n      ...options,\n      stream: true,\n    });\n    return getSSEs(response, getChatCompletionsResult);\n  }\n\n  private setModel(model: string, options: { model?: string }): void {\n    if (!this._isAzure) {\n      options.model = model;\n    }\n  }\n}\n\nfunction createOpenAIEndpoint(version: number): string {\n  return `https://api.openai.com/v${version}`;\n}\n\nfunction isCred(cred: Record<string, any>): cred is TokenCredential | KeyCredential {\n  return isTokenCredential(cred) || cred.key !== undefined;\n}\n"]}