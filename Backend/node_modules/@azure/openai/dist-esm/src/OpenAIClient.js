// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
import { __rest } from "tslib";
/**
 * THIS IS AN AUTO-GENERATED FILE - DO NOT EDIT!
 *
 * Any changes you make here may be lost.
 *
 * If you need to make changes, please do so in the original source file, \{project-root\}/sources/custom
 */
import { isTokenCredential } from "@azure/core-auth";
import { createOpenAI } from "./api/OpenAIContext.js";
import { _getChatCompletionsSend, _getCompletionsSend, beginAzureBatchImageGeneration, getAzureBatchImageGenerationOperationStatus, getChatCompletions, getChatCompletionsResult, getCompletions, getCompletionsResult, getEmbeddings, } from "./api/operations.js";
import { getSSEs } from "./api/sse.js";
export class OpenAIClient {
    constructor(endpointOrOpenAiKey, credOrOptions = {}, options = {}) {
        var _a, _b;
        this._isAzure = false;
        let opts;
        let endpoint;
        let cred;
        if (isCred(credOrOptions)) {
            endpoint = endpointOrOpenAiKey;
            cred = credOrOptions;
            opts = options;
            this._isAzure = true;
        }
        else {
            endpoint = createOpenAIEndpoint(1);
            cred = endpointOrOpenAiKey;
            const { credentials } = credOrOptions, restOpts = __rest(credOrOptions, ["credentials"]);
            opts = Object.assign({ credentials: {
                    apiKeyHeaderName: (_a = credentials === null || credentials === void 0 ? void 0 : credentials.apiKeyHeaderName) !== null && _a !== void 0 ? _a : "Authorization",
                    scopes: credentials === null || credentials === void 0 ? void 0 : credentials.scopes,
                } }, restOpts);
        }
        this._client = createOpenAI(endpoint, cred, Object.assign(Object.assign({}, opts), (this._isAzure
            ? {}
            : {
                additionalPolicies: [
                    ...((_b = opts.additionalPolicies) !== null && _b !== void 0 ? _b : []),
                    {
                        position: "perCall",
                        policy: {
                            name: "openAiEndpoint",
                            sendRequest: (request, next) => {
                                const obj = new URL(request.url);
                                const parts = obj.pathname.split("/");
                                obj.pathname = `/${parts[1]}/${parts.slice(5).join("/")}`;
                                obj.searchParams.delete("api-version");
                                request.url = obj.toString();
                                return next(request);
                            },
                        },
                    },
                ],
            })));
    }
    /** Returns the status of the images operation */
    getAzureBatchImageGenerationOperationStatus(operationId, options = {
        requestOptions: {},
    }) {
        return getAzureBatchImageGenerationOperationStatus(this._client, operationId, options);
    }
    /** Starts the generation of a batch of images from a text caption */
    beginAzureBatchImageGeneration(prompt, options = { requestOptions: {} }) {
        return beginAzureBatchImageGeneration(this._client, prompt, options);
    }
    /**
     * Starts the generation of a batch of images from a text caption
     * @param prompt - The prompt to use for this request.
     * @param options - The options for this image request.
     * @returns The image generation response (containing url or base64 data).
     */
    getImages(prompt, options = { requestOptions: {} }) {
        return beginAzureBatchImageGeneration(this._client, prompt, options);
    }
    /**
     * Returns textual completions as configured for a given prompt.
     * @param deploymentOrModelName - Specifies either the model deployment name (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
     * @param prompt - The prompt to use for this request.
     * @param options - The options for this completions request.
     * @returns The completions for the given prompt.
     */
    getCompletions(deploymentOrModelName, prompt, options = { requestOptions: {} }) {
        this.setModel(deploymentOrModelName, options);
        return getCompletions(this._client, prompt, deploymentOrModelName, options);
    }
    /**
     * Lists the completions tokens as they become available for a given prompt.
     * @param deploymentOrModelName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
     * @param prompt - The prompt to use for this request.
     * @param options - The completions options for this completions request.
     * @returns An asynchronous iterable of completions tokens.
     */
    listCompletions(deploymentOrModelName, prompt, options = {}) {
        this.setModel(deploymentOrModelName, options);
        const response = _getCompletionsSend(this._client, prompt, deploymentOrModelName, Object.assign(Object.assign({}, options), { stream: true }));
        return getSSEs(response, getCompletionsResult);
    }
    /**
     * Return the computed embeddings for a given prompt.
     * @param deploymentOrModelName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
     * @param input - The prompt to use for this request.
     * @param options - The embeddings options for this embeddings request.
     * @returns The embeddings for the given prompt.
     */
    getEmbeddings(deploymentOrModelName, input, options = { requestOptions: {} }) {
        this.setModel(deploymentOrModelName, options);
        return getEmbeddings(this._client, input, deploymentOrModelName, options);
    }
    /**
     * Get chat completions for provided chat context messages.
     * @param deploymentOrModelName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
     * @param messages - The chat context messages to use for this request.
     * @param options - The chat completions options for this completions request.
     * @returns The chat completions for the given chat context messages.
     */
    getChatCompletions(deploymentOrModelName, messages, options = { requestOptions: {} }) {
        this.setModel(deploymentOrModelName, options);
        return getChatCompletions(this._client, messages, deploymentOrModelName, options);
    }
    /**
     * Lists the chat completions tokens as they become available for a chat context.
     * @param deploymentOrModelName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
     * @param messages - The chat context messages to use for this request.
     * @param options - The chat completions options for this chat completions request.
     * @returns An asynchronous iterable of chat completions tokens.
     */
    listChatCompletions(deploymentOrModelName, messages, options = { requestOptions: {} }) {
        this.setModel(deploymentOrModelName, options);
        const response = _getChatCompletionsSend(this._client, messages, deploymentOrModelName, Object.assign(Object.assign({}, options), { stream: true }));
        return getSSEs(response, getChatCompletionsResult);
    }
    setModel(model, options) {
        if (!this._isAzure) {
            options.model = model;
        }
    }
}
function createOpenAIEndpoint(version) {
    return `https://api.openai.com/v${version}`;
}
function isCred(cred) {
    return isTokenCredential(cred) || cred.key !== undefined;
}
//# sourceMappingURL=OpenAIClient.js.map