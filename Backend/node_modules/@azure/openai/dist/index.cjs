'use strict';

Object.defineProperty(exports, '__esModule', { value: true });

var coreAuth = require('@azure/core-auth');
var tslib = require('tslib');
var coreClient = require('@azure-rest/core-client');
var logger$1 = require('@azure/logger');

// Copyright (c) Microsoft Corporation.
const logger = logger$1.createClientLogger("openai");

// Copyright (c) Microsoft Corporation.
/**
 * Initialize a new instance of `OpenAIContext`
 * @param endpoint - Supported Cognitive Services endpoints (protocol and hostname, for example:
 * https://westus.api.cognitive.microsoft.com).
 * @param credentials - uniquely identify client credential
 * @param options - the parameter for all optional parameters
 */
function createClient(endpoint, credentials, options = {}) {
    var _a, _b, _c, _d, _e, _f, _g, _h;
    const baseUrl = (_a = options.baseUrl) !== null && _a !== void 0 ? _a : `${endpoint}/openai`;
    options.apiVersion = (_b = options.apiVersion) !== null && _b !== void 0 ? _b : "2023-06-01-preview";
    options = Object.assign(Object.assign({}, options), { credentials: {
            scopes: (_d = (_c = options.credentials) === null || _c === void 0 ? void 0 : _c.scopes) !== null && _d !== void 0 ? _d : ["https://cognitiveservices.azure.com/.default"],
            apiKeyHeaderName: (_f = (_e = options.credentials) === null || _e === void 0 ? void 0 : _e.apiKeyHeaderName) !== null && _f !== void 0 ? _f : "api-key",
        } });
    const userAgentInfo = `azsdk-js-openai-rest/1.0.0-beta.3`;
    const userAgentPrefix = options.userAgentOptions && options.userAgentOptions.userAgentPrefix
        ? `${options.userAgentOptions.userAgentPrefix} ${userAgentInfo}`
        : `${userAgentInfo}`;
    options = Object.assign(Object.assign({}, options), { userAgentOptions: {
            userAgentPrefix,
        }, loggingOptions: {
            logger: (_h = (_g = options.loggingOptions) === null || _g === void 0 ? void 0 : _g.logger) !== null && _h !== void 0 ? _h : logger.info,
        } });
    const client = coreClient.getClient(baseUrl, credentials, options);
    return client;
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
const responseMap = {
    "POST /deployments/{deploymentId}/embeddings": ["200"],
    "POST /deployments/{deploymentId}/completions": ["200"],
    "POST /deployments/{deploymentId}/chat/completions": ["200"],
    "GET /operations/images/{operationId}": ["200"],
    "POST /images/generations:submit": ["202"],
    "GET /images/generations:submit": ["200", "202"],
};
function isUnexpected(response) {
    const lroOriginal = response.headers["x-ms-original-url"];
    const url = new URL(lroOriginal !== null && lroOriginal !== void 0 ? lroOriginal : response.request.url);
    const method = response.request.method;
    let pathDetails = responseMap[`${method} ${url.pathname}`];
    if (!pathDetails) {
        pathDetails = getParametrizedPathSuccess(method, url.pathname);
    }
    return !pathDetails.includes(response.status);
}
function getParametrizedPathSuccess(method, path) {
    var _a, _b, _c, _d;
    const pathParts = path.split("/");
    // Traverse list to match the longest candidate
    // matchedLen: the length of candidate path
    // matchedValue: the matched status code array
    let matchedLen = -1, matchedValue = [];
    // Iterate the responseMap to find a match
    for (const [key, value] of Object.entries(responseMap)) {
        // Extracting the path from the map key which is in format
        // GET /path/foo
        if (!key.startsWith(method)) {
            continue;
        }
        const candidatePath = getPathFromMapKey(key);
        // Get each part of the url path
        const candidateParts = candidatePath.split("/");
        // track if we have found a match to return the values found.
        let found = true;
        for (let i = candidateParts.length - 1, j = pathParts.length - 1; i >= 1 && j >= 1; i--, j--) {
            if (((_a = candidateParts[i]) === null || _a === void 0 ? void 0 : _a.startsWith("{")) && ((_b = candidateParts[i]) === null || _b === void 0 ? void 0 : _b.indexOf("}")) !== -1) {
                const start = candidateParts[i].indexOf("}") + 1, end = (_c = candidateParts[i]) === null || _c === void 0 ? void 0 : _c.length;
                // If the current part of the candidate is a "template" part
                // Try to use the suffix of pattern to match the path
                // {guid} ==> $
                // {guid}:export ==> :export$
                const isMatched = new RegExp(`${(_d = candidateParts[i]) === null || _d === void 0 ? void 0 : _d.slice(start, end)}`).test(pathParts[j] || "");
                if (!isMatched) {
                    found = false;
                    break;
                }
                continue;
            }
            // If the candidate part is not a template and
            // the parts don't match mark the candidate as not found
            // to move on with the next candidate path.
            if (candidateParts[i] !== pathParts[j]) {
                found = false;
                break;
            }
        }
        // We finished evaluating the current candidate parts
        // Update the matched value if and only if we found the longer pattern
        if (found && candidatePath.length > matchedLen) {
            matchedLen = candidatePath.length;
            matchedValue = value;
        }
    }
    return matchedValue;
}
function getPathFromMapKey(mapKey) {
    const pathStart = mapKey.indexOf("/");
    return mapKey.slice(pathStart);
}

// Copyright (c) Microsoft Corporation.
/** Azure OpenAI APIs for completions and search */
function createOpenAI(endpoint, credential, options = {}) {
    const baseUrl = endpoint;
    const clientContext = createClient(baseUrl, credential, options);
    return clientContext;
}

// Copyright (c) Microsoft Corporation.
function _getEmbeddingsSend(context, input, deploymentId, options = { requestOptions: {} }) {
    var _a, _b, _c;
    return context.path("/deployments/{deploymentId}/embeddings", deploymentId).post({
        allowInsecureConnection: (_a = options.requestOptions) === null || _a === void 0 ? void 0 : _a.allowInsecureConnection,
        skipUrlEncoding: (_b = options.requestOptions) === null || _b === void 0 ? void 0 : _b.skipUrlEncoding,
        headers: Object.assign({}, (_c = options.requestOptions) === null || _c === void 0 ? void 0 : _c.headers),
        body: { user: options === null || options === void 0 ? void 0 : options.user, model: options === null || options === void 0 ? void 0 : options.model, input: input },
    });
}
async function _getEmbeddingsDeserialize(result) {
    var _a;
    if (isUnexpected(result)) {
        throw result.body;
    }
    return {
        data: ((_a = result.body["data"]) !== null && _a !== void 0 ? _a : []).map((p) => ({
            embedding: p["embedding"],
            index: p["index"],
        })),
        usage: {
            promptTokens: result.body.usage["prompt_tokens"],
            totalTokens: result.body.usage["total_tokens"],
        },
    };
}
/** Return the embeddings for a given prompt. */
async function getEmbeddings(context, input, deploymentId, options = { requestOptions: {} }) {
    const result = await _getEmbeddingsSend(context, input, deploymentId, options);
    return _getEmbeddingsDeserialize(result);
}
function _getCompletionsSend(context, prompt, deploymentId, options = { requestOptions: {} }) {
    var _a, _b, _c;
    return context.path("/deployments/{deploymentId}/completions", deploymentId).post({
        allowInsecureConnection: (_a = options.requestOptions) === null || _a === void 0 ? void 0 : _a.allowInsecureConnection,
        skipUrlEncoding: (_b = options.requestOptions) === null || _b === void 0 ? void 0 : _b.skipUrlEncoding,
        headers: Object.assign({}, (_c = options.requestOptions) === null || _c === void 0 ? void 0 : _c.headers),
        body: {
            prompt: prompt,
            max_tokens: options === null || options === void 0 ? void 0 : options.maxTokens,
            temperature: options === null || options === void 0 ? void 0 : options.temperature,
            top_p: options === null || options === void 0 ? void 0 : options.topP,
            logit_bias: options === null || options === void 0 ? void 0 : options.logitBias,
            user: options === null || options === void 0 ? void 0 : options.user,
            n: options === null || options === void 0 ? void 0 : options.n,
            logprobs: options === null || options === void 0 ? void 0 : options.logprobs,
            echo: options === null || options === void 0 ? void 0 : options.echo,
            stop: options === null || options === void 0 ? void 0 : options.stop,
            presence_penalty: options === null || options === void 0 ? void 0 : options.presencePenalty,
            frequency_penalty: options === null || options === void 0 ? void 0 : options.frequencyPenalty,
            best_of: options === null || options === void 0 ? void 0 : options.bestOf,
            stream: options === null || options === void 0 ? void 0 : options.stream,
            model: options === null || options === void 0 ? void 0 : options.model,
        },
    });
}
async function _getCompletionsDeserialize(result) {
    var _a;
    if (isUnexpected(result)) {
        throw result.body;
    }
    return {
        id: result.body["id"],
        created: result.body["created"],
        choices: ((_a = result.body["choices"]) !== null && _a !== void 0 ? _a : []).map((p) => ({
            text: p["text"],
            index: p["index"],
            logprobs: p.logprobs === null
                ? null
                : {
                    tokens: p.logprobs["tokens"],
                    tokenLogprobs: p.logprobs["token_logprobs"],
                    topLogprobs: p.logprobs["top_logprobs"],
                    textOffset: p.logprobs["text_offset"],
                },
            finishReason: p["finish_reason"],
        })),
        usage: {
            completionTokens: result.body.usage["completion_tokens"],
            promptTokens: result.body.usage["prompt_tokens"],
            totalTokens: result.body.usage["total_tokens"],
        },
    };
}
/**
 * Gets completions for the provided input prompts.
 * Completions support a wide variety of tasks and generate text that continues from or "completes"
 * provided prompt data.
 */
async function getCompletions(context, prompt, deploymentId, options = { requestOptions: {} }) {
    const result = await _getCompletionsSend(context, prompt, deploymentId, options);
    return _getCompletionsDeserialize(result);
}
function _getChatCompletionsSend(context, messages, deploymentId, options = { requestOptions: {} }) {
    var _a, _b, _c;
    return context.path("/deployments/{deploymentId}/chat/completions", deploymentId).post({
        allowInsecureConnection: (_a = options.requestOptions) === null || _a === void 0 ? void 0 : _a.allowInsecureConnection,
        skipUrlEncoding: (_b = options.requestOptions) === null || _b === void 0 ? void 0 : _b.skipUrlEncoding,
        headers: Object.assign({}, (_c = options.requestOptions) === null || _c === void 0 ? void 0 : _c.headers),
        body: {
            messages: messages,
            max_tokens: options === null || options === void 0 ? void 0 : options.maxTokens,
            temperature: options === null || options === void 0 ? void 0 : options.temperature,
            top_p: options === null || options === void 0 ? void 0 : options.topP,
            logit_bias: options === null || options === void 0 ? void 0 : options.logitBias,
            user: options === null || options === void 0 ? void 0 : options.user,
            n: options === null || options === void 0 ? void 0 : options.n,
            stop: options === null || options === void 0 ? void 0 : options.stop,
            presence_penalty: options === null || options === void 0 ? void 0 : options.presencePenalty,
            frequency_penalty: options === null || options === void 0 ? void 0 : options.frequencyPenalty,
            stream: options === null || options === void 0 ? void 0 : options.stream,
            model: options === null || options === void 0 ? void 0 : options.model,
        },
    });
}
async function _getChatCompletionsDeserialize(result) {
    var _a;
    if (isUnexpected(result)) {
        throw result.body;
    }
    return {
        id: result.body["id"],
        created: result.body["created"],
        choices: ((_a = result.body["choices"]) !== null && _a !== void 0 ? _a : []).map((p) => {
            var _a, _b, _c, _d;
            return ({
                message: !p.message
                    ? undefined
                    : { role: (_a = p.message) === null || _a === void 0 ? void 0 : _a["role"], content: (_b = p.message) === null || _b === void 0 ? void 0 : _b["content"] },
                index: p["index"],
                finishReason: p["finish_reason"],
                delta: !p.delta ? undefined : { role: (_c = p.delta) === null || _c === void 0 ? void 0 : _c["role"], content: (_d = p.delta) === null || _d === void 0 ? void 0 : _d["content"] },
            });
        }),
        usage: {
            completionTokens: result.body.usage["completion_tokens"],
            promptTokens: result.body.usage["prompt_tokens"],
            totalTokens: result.body.usage["total_tokens"],
        },
    };
}
/**
 * Gets chat completions for the provided chat messages.
 * Completions support a wide variety of tasks and generate text that continues from or "completes"
 * provided prompt data.
 */
async function getChatCompletions(context, messages, deploymentId, options = { requestOptions: {} }) {
    const result = await _getChatCompletionsSend(context, messages, deploymentId, options);
    return _getChatCompletionsDeserialize(result);
}
function _getAzureBatchImageGenerationOperationStatusSend(context, operationId, options = {
    requestOptions: {},
}) {
    var _a, _b, _c;
    return context.path("/operations/images/{operationId}", operationId).get({
        allowInsecureConnection: (_a = options.requestOptions) === null || _a === void 0 ? void 0 : _a.allowInsecureConnection,
        skipUrlEncoding: (_b = options.requestOptions) === null || _b === void 0 ? void 0 : _b.skipUrlEncoding,
        headers: Object.assign({}, (_c = options.requestOptions) === null || _c === void 0 ? void 0 : _c.headers),
    });
}
async function _getAzureBatchImageGenerationOperationStatusDeserialize(result) {
    var _a, _b;
    if (isUnexpected(result)) {
        throw result.body;
    }
    return {
        id: result.body["id"],
        created: result.body["created"],
        expires: result.body["expires"],
        result: !result.body.result
            ? undefined
            : {
                created: (_a = result.body.result) === null || _a === void 0 ? void 0 : _a["created"],
                data: toImageGenerationsData((_b = result.body.result) === null || _b === void 0 ? void 0 : _b["data"]),
            },
        status: result.body["status"],
        error: !result.body.error ? undefined : result.body.error,
    };
}
/**
 * Convert REST-level ImageGenerationsOutput.data to HLC-level ImageGenerations.data
 * see https://github.com/Azure/autorest.typescript/issues/1921
 * @internal
 */
function toImageGenerationsData(input) {
    return input.map(function (locationOrPayload) {
        if ("url" in locationOrPayload) {
            return locationOrPayload;
        }
        else {
            return {
                base64Data: locationOrPayload.b64_json,
            };
        }
    });
}
/** Returns the status of the images operation */
async function getAzureBatchImageGenerationOperationStatus(context, operationId, options = {
    requestOptions: {},
}) {
    const result = await _getAzureBatchImageGenerationOperationStatusSend(context, operationId, options);
    return _getAzureBatchImageGenerationOperationStatusDeserialize(result);
}
function _beginAzureBatchImageGenerationSend(context, prompt, options = { requestOptions: {} }) {
    var _a, _b, _c, _d;
    return context.path("/images/generations:submit").post({
        allowInsecureConnection: (_a = options.requestOptions) === null || _a === void 0 ? void 0 : _a.allowInsecureConnection,
        skipUrlEncoding: (_b = options.requestOptions) === null || _b === void 0 ? void 0 : _b.skipUrlEncoding,
        headers: Object.assign({}, (_c = options.requestOptions) === null || _c === void 0 ? void 0 : _c.headers),
        body: {
            prompt: prompt,
            n: (_d = options.n) !== null && _d !== void 0 ? _d : 1,
            size: options === null || options === void 0 ? void 0 : options.size,
            response_format: options === null || options === void 0 ? void 0 : options.responseFormat,
            user: options === null || options === void 0 ? void 0 : options.user,
        },
    });
}
async function _beginAzureBatchImageGenerationDeserialize(result) {
    var _a, _b;
    if (isUnexpected(result)) {
        throw result.body;
    }
    return {
        id: result.body["id"],
        created: result.body["created"],
        expires: result.body["expires"],
        result: !result.body.result
            ? undefined
            : {
                created: (_a = result.body.result) === null || _a === void 0 ? void 0 : _a["created"],
                data: toImageGenerationsData((_b = result.body.result) === null || _b === void 0 ? void 0 : _b["data"]),
            },
        status: result.body["status"],
        error: !result.body.error ? undefined : result.body.error,
    };
}
/** Starts the generation of a batch of images from a text caption */
async function beginAzureBatchImageGeneration(context, prompt, options = { requestOptions: {} }) {
    const result = await _beginAzureBatchImageGenerationSend(context, prompt, options);
    return _beginAzureBatchImageGenerationDeserialize(result);
}
function getCompletionsResult(body) {
    var _a;
    return {
        id: body["id"],
        created: body["created"],
        choices: ((_a = body["choices"]) !== null && _a !== void 0 ? _a : []).map((p) => ({
            text: p["text"],
            index: p["index"],
            logprobs: p.logprobs === null
                ? null
                : {
                    tokens: p.logprobs["tokens"],
                    tokenLogprobs: p.logprobs["token_logprobs"],
                    topLogprobs: p.logprobs["top_logprobs"],
                    textOffset: p.logprobs["text_offset"],
                },
            finishReason: p["finish_reason"],
        })),
    };
}
function getChatCompletionsResult(body) {
    var _a;
    return {
        id: body["id"],
        created: body["created"],
        choices: ((_a = body["choices"]) !== null && _a !== void 0 ? _a : []).map((p) => {
            var _a, _b, _c, _d;
            return ({
                message: !p.message
                    ? undefined
                    : { role: (_a = p.message) === null || _a === void 0 ? void 0 : _a["role"], content: (_b = p.message) === null || _b === void 0 ? void 0 : _b["content"] },
                index: p["index"],
                finishReason: p["finish_reason"],
                delta: !p.delta ? undefined : { role: (_c = p.delta) === null || _c === void 0 ? void 0 : _c["role"], content: (_d = p.delta) === null || _d === void 0 ? void 0 : _d["content"] },
            });
        }),
    };
}

// Copyright (c) Microsoft Corporation.
function getStream(response) {
    return tslib.__asyncGenerator(this, arguments, function* getStream_1() {
        var _a, e_1, _b, _c;
        const stream = (yield tslib.__await(response.asNodeStream())).body;
        if (!stream)
            throw new Error("No stream found in response. Did you enable the stream option?");
        try {
            for (var _d = true, stream_1 = tslib.__asyncValues(stream), stream_1_1; stream_1_1 = yield tslib.__await(stream_1.next()), _a = stream_1_1.done, !_a;) {
                _c = stream_1_1.value;
                _d = false;
                try {
                    const chunk = _c;
                    yield yield tslib.__await(chunk.toString());
                }
                finally {
                    _d = true;
                }
            }
        }
        catch (e_1_1) { e_1 = { error: e_1_1 }; }
        finally {
            try {
                if (!_d && !_a && (_b = stream_1.return)) yield tslib.__await(_b.call(stream_1));
            }
            finally { if (e_1) throw e_1.error; }
        }
    });
}

// Copyright (c) Microsoft Corporation.
async function getSSEs(response, toEvent) {
    const stream = getStream(response);
    let prevLineIfIncomplete = "";
    let started = false;
    return streamToEvents(stream, (chunk) => {
        if (!chunk.startsWith("data: ") && !started) {
            throw new Error(chunk);
        }
        started = true;
        const events = [];
        for (let str of chunk.split("\n\n")) {
            if (str.startsWith("data: ")) {
                str = str.slice(6);
            }
            if (["", "[DONE]", "[DONE]\n"].includes(str)) {
                return events;
            }
            try {
                const event = JSON.parse(prevLineIfIncomplete + str);
                prevLineIfIncomplete = "";
                events.push(toEvent(event));
            }
            catch (e) {
                prevLineIfIncomplete += str;
            }
        }
        return events;
    });
}
function streamToEvents(stream, processChunk) {
    return tslib.__asyncGenerator(this, arguments, function* streamToEvents_1() {
        var _a, e_1, _b, _c;
        try {
            for (var _d = true, stream_1 = tslib.__asyncValues(stream), stream_1_1; stream_1_1 = yield tslib.__await(stream_1.next()), _a = stream_1_1.done, !_a;) {
                _c = stream_1_1.value;
                _d = false;
                try {
                    const chunk = _c;
                    yield tslib.__await(yield* tslib.__asyncDelegator(tslib.__asyncValues(processChunk(chunk))));
                }
                finally {
                    _d = true;
                }
            }
        }
        catch (e_1_1) { e_1 = { error: e_1_1 }; }
        finally {
            try {
                if (!_d && !_a && (_b = stream_1.return)) yield tslib.__await(_b.call(stream_1));
            }
            finally { if (e_1) throw e_1.error; }
        }
    });
}

// Copyright (c) Microsoft Corporation.
class OpenAIClient {
    constructor(endpointOrOpenAiKey, credOrOptions = {}, options = {}) {
        var _a, _b;
        this._isAzure = false;
        let opts;
        let endpoint;
        let cred;
        if (isCred(credOrOptions)) {
            endpoint = endpointOrOpenAiKey;
            cred = credOrOptions;
            opts = options;
            this._isAzure = true;
        }
        else {
            endpoint = createOpenAIEndpoint(1);
            cred = endpointOrOpenAiKey;
            const { credentials } = credOrOptions, restOpts = tslib.__rest(credOrOptions, ["credentials"]);
            opts = Object.assign({ credentials: {
                    apiKeyHeaderName: (_a = credentials === null || credentials === void 0 ? void 0 : credentials.apiKeyHeaderName) !== null && _a !== void 0 ? _a : "Authorization",
                    scopes: credentials === null || credentials === void 0 ? void 0 : credentials.scopes,
                } }, restOpts);
        }
        this._client = createOpenAI(endpoint, cred, Object.assign(Object.assign({}, opts), (this._isAzure
            ? {}
            : {
                additionalPolicies: [
                    ...((_b = opts.additionalPolicies) !== null && _b !== void 0 ? _b : []),
                    {
                        position: "perCall",
                        policy: {
                            name: "openAiEndpoint",
                            sendRequest: (request, next) => {
                                const obj = new URL(request.url);
                                const parts = obj.pathname.split("/");
                                obj.pathname = `/${parts[1]}/${parts.slice(5).join("/")}`;
                                obj.searchParams.delete("api-version");
                                request.url = obj.toString();
                                return next(request);
                            },
                        },
                    },
                ],
            })));
    }
    /** Returns the status of the images operation */
    getAzureBatchImageGenerationOperationStatus(operationId, options = {
        requestOptions: {},
    }) {
        return getAzureBatchImageGenerationOperationStatus(this._client, operationId, options);
    }
    /** Starts the generation of a batch of images from a text caption */
    beginAzureBatchImageGeneration(prompt, options = { requestOptions: {} }) {
        return beginAzureBatchImageGeneration(this._client, prompt, options);
    }
    /**
     * Starts the generation of a batch of images from a text caption
     * @param prompt - The prompt to use for this request.
     * @param options - The options for this image request.
     * @returns The image generation response (containing url or base64 data).
     */
    getImages(prompt, options = { requestOptions: {} }) {
        return beginAzureBatchImageGeneration(this._client, prompt, options);
    }
    /**
     * Returns textual completions as configured for a given prompt.
     * @param deploymentOrModelName - Specifies either the model deployment name (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
     * @param prompt - The prompt to use for this request.
     * @param options - The options for this completions request.
     * @returns The completions for the given prompt.
     */
    getCompletions(deploymentOrModelName, prompt, options = { requestOptions: {} }) {
        this.setModel(deploymentOrModelName, options);
        return getCompletions(this._client, prompt, deploymentOrModelName, options);
    }
    /**
     * Lists the completions tokens as they become available for a given prompt.
     * @param deploymentOrModelName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
     * @param prompt - The prompt to use for this request.
     * @param options - The completions options for this completions request.
     * @returns An asynchronous iterable of completions tokens.
     */
    listCompletions(deploymentOrModelName, prompt, options = {}) {
        this.setModel(deploymentOrModelName, options);
        const response = _getCompletionsSend(this._client, prompt, deploymentOrModelName, Object.assign(Object.assign({}, options), { stream: true }));
        return getSSEs(response, getCompletionsResult);
    }
    /**
     * Return the computed embeddings for a given prompt.
     * @param deploymentOrModelName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
     * @param input - The prompt to use for this request.
     * @param options - The embeddings options for this embeddings request.
     * @returns The embeddings for the given prompt.
     */
    getEmbeddings(deploymentOrModelName, input, options = { requestOptions: {} }) {
        this.setModel(deploymentOrModelName, options);
        return getEmbeddings(this._client, input, deploymentOrModelName, options);
    }
    /**
     * Get chat completions for provided chat context messages.
     * @param deploymentOrModelName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
     * @param messages - The chat context messages to use for this request.
     * @param options - The chat completions options for this completions request.
     * @returns The chat completions for the given chat context messages.
     */
    getChatCompletions(deploymentOrModelName, messages, options = { requestOptions: {} }) {
        this.setModel(deploymentOrModelName, options);
        return getChatCompletions(this._client, messages, deploymentOrModelName, options);
    }
    /**
     * Lists the chat completions tokens as they become available for a chat context.
     * @param deploymentOrModelName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
     * @param messages - The chat context messages to use for this request.
     * @param options - The chat completions options for this chat completions request.
     * @returns An asynchronous iterable of chat completions tokens.
     */
    listChatCompletions(deploymentOrModelName, messages, options = { requestOptions: {} }) {
        this.setModel(deploymentOrModelName, options);
        const response = _getChatCompletionsSend(this._client, messages, deploymentOrModelName, Object.assign(Object.assign({}, options), { stream: true }));
        return getSSEs(response, getChatCompletionsResult);
    }
    setModel(model, options) {
        if (!this._isAzure) {
            options.model = model;
        }
    }
}
function createOpenAIEndpoint(version) {
    return `https://api.openai.com/v${version}`;
}
function isCred(cred) {
    return coreAuth.isTokenCredential(cred) || cred.key !== undefined;
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * The OpenAIKeyCredential class represents an OpenAI API key
 * and is used to authenticate into an OpenAI client for
 * an OpenAI endpoint.
 */
class OpenAIKeyCredential {
    /**
     * Create an instance of an AzureKeyCredential for use
     * with a service client.
     *
     * @param key - The initial value of the key to use in authentication
     */
    constructor(key) {
        if (!key) {
            throw new Error("key must be a non-empty string");
        }
        this._key = createKey(key);
    }
    /**
     * The value of the key to be used in authentication
     */
    get key() {
        return this._key;
    }
    /**
     * Change the value of the key.
     *
     * Updates will take effect upon the next request after
     * updating the key value.
     *
     * @param newKey - The new key value to be used
     */
    update(newKey) {
        this._key = createKey(newKey);
    }
}
function createKey(key) {
    return key.startsWith("Bearer ") ? key : `Bearer ${key}`;
}

Object.defineProperty(exports, 'AzureKeyCredential', {
    enumerable: true,
    get: function () { return coreAuth.AzureKeyCredential; }
});
exports.OpenAIClient = OpenAIClient;
exports.OpenAIKeyCredential = OpenAIKeyCredential;
//# sourceMappingURL=index.cjs.map
