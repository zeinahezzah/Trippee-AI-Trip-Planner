/**
 * THIS IS AN AUTO-GENERATED FILE - DO NOT EDIT!
 *
 * Any changes you make here may be lost.
 *
 * If you need to make changes, please do so in the original source file, \{project-root\}/sources/custom
 */
import { KeyCredential, TokenCredential } from "@azure/core-auth";
import { ChatCompletions, ChatMessage, Completions, Embeddings, GetAzureBatchImageGenerationOperationStatusOptions, GetChatCompletionsOptions, GetCompletionsOptions, GetEmbeddingsOptions, ImageGenerationOptions, ImageGenerationResponse, OpenAIClientOptions } from "./index.js";
export { OpenAIClientOptions } from "./api/OpenAIContext.js";
export declare class OpenAIClient {
    private _client;
    private _isAzure;
    /**
     * Initializes an instance of OpenAIClient for use with an Azure OpenAI resource.
     * @param endpoint - The URI for an Azure OpenAI resource, including protocol and hostname.
     *                 For example: https://my-resource.openai.azure.com.
     * @param credential - A key credential used to authenticate to an Azure OpenAI resource.
     * @param options - The options for configuring the client.
     * @remarks
     *   This constructor initializes an OpenAIClient object that can only be used with Azure OpenAI resources.
     *   To use OpenAIClient with a non-Azure OpenAI inference endpoint, use a constructor that accepts a non-Azure OpenAI API key instead.
     */
    constructor(endpoint: string, credential: KeyCredential, options?: OpenAIClientOptions);
    /**
     * Initializes an instance of OpenAIClient for use with an Azure OpenAI resource.
     * @param endpoint - The URI for an Azure OpenAI resource, including protocol and hostname.
     *                 For example: https://my-resource.openai.azure.com.
     * @param credential - A token credential used to authenticate with an Azure OpenAI resource.
     * @param options - The options for configuring the client.
     */
    constructor(endpoint: string, credential: TokenCredential, options?: OpenAIClientOptions);
    /**
     * Initializes an instance of OpenAIClient for use with the non-Azure OpenAI endpoint.
     * @param openAiApiKey - The API key to use when connecting to the non-Azure OpenAI endpoint.
     * @param options - The options for configuring the client.
     * @remarks
     *   OpenAIClient objects initialized with this constructor can only be used with the non-Azure OpenAI inference endpoint.
     *   To use OpenAIClient with an Azure OpenAI resource, use a constructor that accepts a resource URI and Azure authentication credential instead.
     */
    constructor(openAiApiKey: KeyCredential, options?: OpenAIClientOptions);
    /** Returns the status of the images operation */
    getAzureBatchImageGenerationOperationStatus(operationId: string, options?: GetAzureBatchImageGenerationOperationStatusOptions): Promise<ImageGenerationResponse>;
    /** Starts the generation of a batch of images from a text caption */
    beginAzureBatchImageGeneration(prompt: string, options?: ImageGenerationOptions): Promise<ImageGenerationResponse>;
    /**
     * Starts the generation of a batch of images from a text caption
     * @param prompt - The prompt to use for this request.
     * @param options - The options for this image request.
     * @returns The image generation response (containing url or base64 data).
     */
    getImages(prompt: string, options?: ImageGenerationOptions): Promise<ImageGenerationResponse>;
    /**
     * Returns textual completions as configured for a given prompt.
     * @param deploymentOrModelName - Specifies either the model deployment name (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
     * @param prompt - The prompt to use for this request.
     * @param options - The options for this completions request.
     * @returns The completions for the given prompt.
     */
    getCompletions(deploymentOrModelName: string, prompt: string[], options?: GetCompletionsOptions): Promise<Completions>;
    /**
     * Lists the completions tokens as they become available for a given prompt.
     * @param deploymentOrModelName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
     * @param prompt - The prompt to use for this request.
     * @param options - The completions options for this completions request.
     * @returns An asynchronous iterable of completions tokens.
     */
    listCompletions(deploymentOrModelName: string, prompt: string[], options?: GetCompletionsOptions): Promise<AsyncIterable<Omit<Completions, "usage">>>;
    /**
     * Return the computed embeddings for a given prompt.
     * @param deploymentOrModelName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
     * @param input - The prompt to use for this request.
     * @param options - The embeddings options for this embeddings request.
     * @returns The embeddings for the given prompt.
     */
    getEmbeddings(deploymentOrModelName: string, input: string[], options?: GetEmbeddingsOptions): Promise<Embeddings>;
    /**
     * Get chat completions for provided chat context messages.
     * @param deploymentOrModelName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
     * @param messages - The chat context messages to use for this request.
     * @param options - The chat completions options for this completions request.
     * @returns The chat completions for the given chat context messages.
     */
    getChatCompletions(deploymentOrModelName: string, messages: ChatMessage[], options?: GetChatCompletionsOptions): Promise<ChatCompletions>;
    /**
     * Lists the chat completions tokens as they become available for a chat context.
     * @param deploymentOrModelName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
     * @param messages - The chat context messages to use for this request.
     * @param options - The chat completions options for this chat completions request.
     * @returns An asynchronous iterable of chat completions tokens.
     */
    listChatCompletions(deploymentOrModelName: string, messages: ChatMessage[], options?: GetChatCompletionsOptions): Promise<AsyncIterable<Omit<ChatCompletions, "usage">>>;
    private setModel;
}
//# sourceMappingURL=OpenAIClient.d.ts.map